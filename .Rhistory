Stein <- function(w){
Pi <- exp(Pred%*%w)/(1+exp(Pred%*%w))
ss <- -sum( y*log(Pi)+(1-y)*log(1-Pi) )
ss
}
model <- optim(w,fn=Stein,method="L-BFGS-B",lower=rep(0,len=m),upper=rep(1,len=m))
w <- model$par
######################################
Pred <- PRED%*%w
EProb <- exp(Pred)/(1+exp(Pred))
plot(EProb,y,xlab="Estimated probability",ylab="Observed response")
print(as.numeric(cor(TProb,EProb)))
}
for(n.seed in 1:100){
set.seed(n.seed)
n <- 100
p <- 1000
AX <- matrix(rnorm(n*p,0,1),ncol=p)
SSS <- 50 #Ture numb para
BETA <- rnorm(SSS,0,1)
z <- AX[,1:SSS]%*%BETA
TProb <- exp(z)/(1+exp(z))
y <- as.numeric(runif(n,0,1)<TProb)
p <- PP <- ncol(AX)
######################################
COV <- rep(0,len=PP)
for(i in 1:PP){
fit <- glm(y~AX[,i],family=binomial())
COV[i] <- (summary(fit)$coefficients)[2,4]
}
a <- cbind(1:PP,COV)
COV <- a[order(a[,2],decreasing=F),1:2]
NN <- NumbPred <- 10 #The number of predictors
KK <- trunc(sum(COV[,2]<=0.05)/NN)
######################################
Pred <- matrix(0,n,KK); PRED <- matrix(0,n,KK)
COM <- 1
USE <- COV[(NN*(COM-1)+1):(NN*COM),1]; E <- as.matrix(AX[,USE])
for(i in 1:n){
fit <- glm(y[-i]~E[-i,]+0,binomial(link="logit"))
Pred[i,COM] <- sum( E[i,]*(fit$coefficients) )
}
fit <- glm(y~E+0,binomial(link="logit"))
PRED[,COM] <- E%*%(fit$coefficients)
for(m in 2:KK){
COM <- m
USE <- COV[(NN*(COM-1)+1):(NN*COM),1]; E <- as.matrix(AX[,USE])
for(i in 1:n){
fit <- glm(y[-i]~E[-i,]+0,binomial(link="logit"))
Pred[i,COM] <- sum( E[i,]*(fit$coefficients) )
}
fit <- glm(y~E+0,binomial(link="logit"))
PRED[,COM] <- E%*%(fit$coefficients)
}
######################################
w <- rep(0.5,len=KK)
Stein <- function(w){
Pi <- exp(Pred%*%w)/(1+exp(Pred%*%w))
ss <- -sum( y*log(Pi)+(1-y)*log(1-Pi) )
ss
}
model <- optim(w,fn=Stein,method="L-BFGS-B",lower=rep(0,len=m),upper=rep(1,len=m))
w <- model$par
######################################
Pred <- PRED%*%w
EProb <- exp(Pred)/(1+exp(Pred))
plot(EProb,y,xlab="Estimated probability",ylab="Observed response")
print(as.numeric(cor(TProb,EProb)))
}
for(n.seed in 1:10000){
t <- runif(1)
set.seed(t)
n <- 100
p <- 1000
AX <- matrix(rnorm(n*p,0,1),ncol=p)
SSS <- 50 #Ture numb para
BETA <- rnorm(SSS,0,1)
z <- AX[,1:SSS]%*%BETA
TProb <- exp(z)/(1+exp(z))
y <- as.numeric(runif(n,0,1)<TProb)
p <- PP <- ncol(AX)
######################################
COV <- rep(0,len=PP)
for(i in 1:PP){
fit <- glm(y~AX[,i],family=binomial())
COV[i] <- (summary(fit)$coefficients)[2,4]
}
a <- cbind(1:PP,COV)
COV <- a[order(a[,2],decreasing=F),1:2]
NN <- NumbPred <- 10 #The number of predictors
KK <- trunc(sum(COV[,2]<=0.05)/NN)
######################################
Pred <- matrix(0,n,KK); PRED <- matrix(0,n,KK)
COM <- 1
USE <- COV[(NN*(COM-1)+1):(NN*COM),1]; E <- as.matrix(AX[,USE])
for(i in 1:n){
fit <- glm(y[-i]~E[-i,]+0,binomial(link="logit"))
Pred[i,COM] <- sum( E[i,]*(fit$coefficients) )
}
fit <- glm(y~E+0,binomial(link="logit"))
PRED[,COM] <- E%*%(fit$coefficients)
for(m in 2:KK){
COM <- m
USE <- COV[(NN*(COM-1)+1):(NN*COM),1]; E <- as.matrix(AX[,USE])
for(i in 1:n){
fit <- glm(y[-i]~E[-i,]+0,binomial(link="logit"))
Pred[i,COM] <- sum( E[i,]*(fit$coefficients) )
}
fit <- glm(y~E+0,binomial(link="logit"))
PRED[,COM] <- E%*%(fit$coefficients)
}
######################################
w <- rep(0.5,len=KK)
Stein <- function(w){
Pi <- exp(Pred%*%w)/(1+exp(Pred%*%w))
ss <- -sum( y*log(Pi)+(1-y)*log(1-Pi) )
ss
}
model <- optim(w,fn=Stein,method="L-BFGS-B",lower=rep(0,len=m),upper=rep(1,len=m))
w <- model$par
######################################
Pred <- PRED%*%w
EProb <- exp(Pred)/(1+exp(Pred))
plot(EProb,y,xlab="Estimated probability",ylab="Observed response")
print(as.numeric(cor(TProb,EProb)))
}
for(n.seed in 1:10000){
set.seed(n.seed)
n <- 100
p <- 1000
AX <- matrix(rnorm(n*p,0,1),ncol=p)
SSS <- 50 #Ture numb para
BETA <- rnorm(SSS,0,1)
z <- AX[,1:SSS]%*%BETA
TProb <- exp(z)/(1+exp(z))
y <- as.numeric(runif(n,0,1)<TProb)
p <- PP <- ncol(AX)
######################################
COV <- rep(0,len=PP)
for(i in 1:PP){
fit <- glm(y~AX[,i],family=binomial())
COV[i] <- (summary(fit)$coefficients)[2,4]
}
a <- cbind(1:PP,COV)
COV <- a[order(a[,2],decreasing=F),1:2]
NN <- NumbPred <- 10 #The number of predictors
KK <- trunc(sum(COV[,2]<=0.05)/NN)
######################################
Pred <- matrix(0,n,KK); PRED <- matrix(0,n,KK)
COM <- 1
USE <- COV[(NN*(COM-1)+1):(NN*COM),1]; E <- as.matrix(AX[,USE])
for(i in 1:n){
fit <- glm(y[-i]~E[-i,]+0,binomial(link="logit"))
Pred[i,COM] <- sum( E[i,]*(fit$coefficients) )
}
fit <- glm(y~E+0,binomial(link="logit"))
PRED[,COM] <- E%*%(fit$coefficients)
for(m in 2:KK){
COM <- m
USE <- COV[(NN*(COM-1)+1):(NN*COM),1]; E <- as.matrix(AX[,USE])
for(i in 1:n){
fit <- glm(y[-i]~E[-i,]+0,binomial(link="logit"))
Pred[i,COM] <- sum( E[i,]*(fit$coefficients) )
}
fit <- glm(y~E+0,binomial(link="logit"))
PRED[,COM] <- E%*%(fit$coefficients)
}
######################################
w <- rep(0.5,len=KK)
Stein <- function(w){
Pi <- exp(Pred%*%w)/(1+exp(Pred%*%w))
ss <- -sum( y*log(Pi)+(1-y)*log(1-Pi) )
ss
}
model <- optim(w,fn=Stein,method="L-BFGS-B",lower=rep(0,len=m),upper=rep(1,len=m))
w <- model$par
######################################
Pred <- PRED%*%w
EProb <- exp(Pred)/(1+exp(Pred))
plot(EProb,y,xlab="Estimated probability",ylab="Observed response")
print(as.numeric(cor(TProb,EProb)))
}
set.seed(1359)
n <- 100
p <- 1000
AX <- matrix(rnorm(n*p,0,1),ncol=p)
SSS <- 50 #Ture numb para
BETA <- rnorm(SSS,0,1)
z <- AX[,1:SSS]%*%BETA
TProb <- exp(z)/(1+exp(z))
y <- as.numeric(runif(n,0,1)<TProb)
p <- PP <- ncol(AX)
######################################
COV <- rep(0,len=PP)
for(i in 1:PP){
fit <- glm(y~AX[,i],family=binomial())
COV[i] <- (summary(fit)$coefficients)[2,4]
}
a <- cbind(1:PP,COV)
COV <- a[order(a[,2],decreasing=F),1:2]
NN <- NumbPred <- 10 #The number of predictors
KK <- trunc(sum(COV[,2]<=0.05)/NN)
######################################
Pred <- matrix(0,n,KK); PRED <- matrix(0,n,KK)
COM <- 1
USE <- COV[(NN*(COM-1)+1):(NN*COM),1]; E <- as.matrix(AX[,USE])
for(i in 1:n){
fit <- glm(y[-i]~E[-i,]+0,binomial(link="logit"))
Pred[i,COM] <- sum( E[i,]*(fit$coefficients) )
}
fit <- glm(y~E+0,binomial(link="logit"))
PRED[,COM] <- E%*%(fit$coefficients)
for(m in 2:KK){
COM <- m
USE <- COV[(NN*(COM-1)+1):(NN*COM),1]; E <- as.matrix(AX[,USE])
for(i in 1:n){
fit <- glm(y[-i]~E[-i,]+0,binomial(link="logit"))
Pred[i,COM] <- sum( E[i,]*(fit$coefficients) )
}
fit <- glm(y~E+0,binomial(link="logit"))
PRED[,COM] <- E%*%(fit$coefficients)
}
######################################
w <- rep(0.5,len=KK)
Stein <- function(w){
Pi <- exp(Pred%*%w)/(1+exp(Pred%*%w))
ss <- -sum( y*log(Pi)+(1-y)*log(1-Pi) )
ss
}
model <- optim(w,fn=Stein,method="L-BFGS-B",lower=rep(0,len=m),upper=rep(1,len=m))
w <- model$par
######################################
Pred <- PRED%*%w
EProb <- exp(Pred)/(1+exp(Pred))
plot(EProb,y,xlab="Estimated probability",ylab="Observed response")
print(as.numeric(cor(TProb,EProb)))
set.seed(1359)
n <- 100
p <- 1000
AX <- matrix(rnorm(n*p,0,1),ncol=p)
SSS <- 50 #Ture numb para
BETA <- rnorm(SSS,0,1)
z <- AX[,1:SSS]%*%BETA
TProb <- exp(z)/(1+exp(z))
y <- as.numeric(runif(n,0,1)<TProb)
p <- PP <- ncol(AX)
######################################
COV <- rep(0,len=PP)
for(i in 1:PP){
fit <- glm(y~AX[,i],family=binomial())
COV[i] <- (summary(fit)$coefficients)[2,4]
}
a <- cbind(1:PP,COV)
COV <- a[order(a[,2],decreasing=F),1:2]
NN <- NumbPred <- 10 #The number of predictors
KK <- trunc(sum(COV[,2]<=0.05)/NN)
######################################
Pred <- matrix(0,n,KK); PRED <- matrix(0,n,KK)
COM <- 1
USE <- COV[(NN*(COM-1)+1):(NN*COM),1]; E <- as.matrix(AX[,USE])
for(i in 1:n){
fit <- glm(y[-i]~E[-i,]+0,binomial(link="logit"))
Pred[i,COM] <- sum( E[i,]*(fit$coefficients) )
}
fit <- glm(y~E+0,binomial(link="logit"))
PRED[,COM] <- E%*%(fit$coefficients)
for(m in 2:KK){
COM <- m
USE <- COV[(NN*(COM-1)+1):(NN*COM),1]; E <- as.matrix(AX[,USE])
for(i in 1:n){
fit <- glm(y[-i]~E[-i,]+0,binomial(link="logit"))
Pred[i,COM] <- sum( E[i,]*(fit$coefficients) )
}
fit <- glm(y~E+0,binomial(link="logit"))
PRED[,COM] <- E%*%(fit$coefficients)
}
######################################
w <- rep(0.5,len=KK)
Stein <- function(w){
Pi <- exp(Pred%*%w)/(1+exp(Pred%*%w))
ss <- -sum( y*log(Pi)+(1-y)*log(1-Pi) )
ss
}
model <- optim(w,fn=Stein,method="L-BFGS-B",lower=rep(0,len=m),upper=rep(1,len=m))
w <- model$par
######################################
Pred <- PRED%*%w
EProb <- exp(Pred)/(1+exp(Pred))
plot(EProb,y,xlab="Estimated probability",ylab="Observed response")
print(as.numeric(cor(TProb,EProb)))
######################################
set.seed(1359)     #choose a seed
######################################
n <- 100
p <- 1000
AX <- matrix(rnorm(n*p,0,1),ncol=p)
SSS <- 50 #Ture numb para
BETA <- rnorm(SSS,0,1)
z <- AX[,1:SSS]%*%BETA
TProb <- exp(z)/(1+exp(z))
y <- as.numeric(runif(n,0,1)<TProb)
p <- PP <- ncol(AX)
######################################
COV <- rep(0,len=PP)
for(i in 1:PP){
fit <- glm(y~AX[,i],family=binomial())
COV[i] <- (summary(fit)$coefficients)[2,4]
}
a <- cbind(1:PP,COV)
COV <- a[order(a[,2],decreasing=F),1:2]
NN <- NumbPred <- 10 #The number of predictors
KK <- trunc(sum(COV[,2]<=0.05)/NN)
######################################
Pred <- matrix(0,n,KK); PRED <- matrix(0,n,KK)
COM <- 1
USE <- COV[(NN*(COM-1)+1):(NN*COM),1]; E <- as.matrix(AX[,USE])
for(i in 1:n){
fit <- glm(y[-i]~E[-i,]+0,binomial(link="logit"))
Pred[i,COM] <- sum( E[i,]*(fit$coefficients) )
}
fit <- glm(y~E+0,binomial(link="logit"))
PRED[,COM] <- E%*%(fit$coefficients)
for(m in 2:KK){
COM <- m
USE <- COV[(NN*(COM-1)+1):(NN*COM),1]; E <- as.matrix(AX[,USE])
for(i in 1:n){
fit <- glm(y[-i]~E[-i,]+0,binomial(link="logit"))
Pred[i,COM] <- sum( E[i,]*(fit$coefficients) )
}
fit <- glm(y~E+0,binomial(link="logit"))
PRED[,COM] <- E%*%(fit$coefficients)
}
######################################
w <- rep(0.5,len=KK)
Stein <- function(w){
Pi <- exp(Pred%*%w)/(1+exp(Pred%*%w))
ss <- -sum( y*log(Pi)+(1-y)*log(1-Pi) )
ss
}
model <- optim(w,fn=Stein,method="L-BFGS-B",lower=rep(0,len=m),upper=rep(1,len=m))
w <- model$par
######################################
Pred <- PRED%*%w
EProb <- exp(Pred)/(1+exp(Pred))
plot(EProb,y,xlab="Estimated probability",ylab="Observed response")
source("SourceAoS.txt")
setwd("H:/UbuntuRv2/Gibbs-sampler-algorithm/MA-Tingjin5")
source("SourceAoS.txt")
source("SourceAoS_seed.txt")
setwd("H:/UbuntuRv2/STC/TCG")
#data set ---------------------------------------
tcg <- read.csv("TC_data_12h_AR.csv")
#AR ------------------------------------------
#remove highly correlated predictors
tmp <- cor(x.all)
tmp[upper.tri(tmp)] <- 0
diag(tmp) <- 0
data <- tcg[, !apply(tmp, 2, function(x) any(abs(x) > 0.95, na.rm = TRUE))]
#AR ------------------------------------------
#remove highly correlated predictors
tmp <- cor(tcg)
tmp[upper.tri(tmp)] <- 0
diag(tmp) <- 0
data <- tcg[, !apply(tmp, 2, function(x) any(abs(x) > 0.95, na.rm = TRUE))]
n <- dim(data)[1]
p <- dim(data)[2]
#train & test
index <- c(154:238,2032:2504)
data.train <- data[-index,]
data.test  <- data[index,]
data.train$TC_genesis <- as.factor(data.train$TC_genesis)
z.smote <- SMOTE(TC_genesis~., data.train)
library(DMwR)
z.smote <- SMOTE(TC_genesis~., data.train)
#train set
y <- as.numeric(z.smote[,121])-1
table(y)
x <- as.matrix(z.smote[,-121])
load("H:/UbuntuRv2/STC/TCG/tcg_ar_method_1_1.RData")
Pred <- predicts.Gibbs(data.test, m.block)
binary.table <- function(y, y_pred, type = c("link", "response")){
m <- matrix(rep(0,4), ncol = 2)
rownames(m) <- c("Positive", "Negative")
colnames(m) <- c("True", "False")
if(type == "link"){
m[1,1] <- sum(y == 1 & y_pred > 0)
m[1,2] <- sum(y == 0 & y_pred > 0)
m[2,1] <- sum(y == 1 & y_pred < 0)
m[2,2] <- sum(y == 0 & y_pred < 0)
}
else{
m[1,1] <- sum(y == 1 & y_pred > 0.5)
m[1,2] <- sum(y == 0 & y_pred > 0.5)
m[2,1] <- sum(y == 1 & y_pred < 0.5)
m[2,2] <- sum(y == 0 & y_pred < 0.5)
}
return(m)
}
binary.table(data.test$TC_genesis, Pred, type = "response")
stargazer::stargazer(binary.table(data.test$TC_genesis, Pred, type = "response"))
load("H:/UbuntuRv2/STC/TCG/tcg_ar_method_2_1.RData")
Pred <- predicts.Gibbs(data.test, m.block)
stargazer::stargazer(binary.table(data.test$TC_genesis, Pred, type = "response"))
#SMOTE training ----------------------------------
data.train$TC_genesis <- as.factor(data.train$TC_genesis)
z.smote <- SMOTE(TC_genesis~., data.train)
PredT <- vector()
for(i in 1:length(m.block$c.models$weights)){
fit <- m.block$c.models$models[[i]]
x.var <- as.numeric(colnames(fit$model[,-1]))
z.new <- z.smote[,c(x.var,p)]
fit0 <- glm(TC_genesis~., data = z.new, family = binomial())
pred0 <- predict(fit0, data.test[,x.var], type = "link")
PredT <- cbind(PredT, pred0)
}
Pred.t <- PredT %*% m.block$c.models$weights
save.image("tcg_ar_method_3_1.RData")
m.block$c.models$weights
binary.table(data.test$TC_genesis, Pred.t, type = "link")
stargazer::stargazer(binary.table(data.test$TC_genesis, Pred.t, type = "link"))
load("H:/UbuntuRv2/STC/TCG/tcg_ar_method_1_1.RData")
load("H:/UbuntuRv2/STC/TCG/tcg_ar_method_1_1.RData")
fit <- m.block$c.models$models[[1]]
dim(fit$model)
head(fit$model)
P0 <- vector()
for(i in 1:length(m.block$c.models$weights)){
fit <- m.block$c.models$models[[i]]
p1 <- dim(fit$model)-1
PredT <- cbind(P0, p1)
}
p2 <- P0 %*% m.block$c.models$weights
P0 <- vector()
for(i in 1:length(m.block$c.models$weights)){
fit <- m.block$c.models$models[[i]]
p1 <- dim(fit$model)-1
PredT <- cbind(P0, p1)
}
P0 <- vector()
for(i in 1:length(m.block$c.models$weights)){
fit <- m.block$c.models$models[[i]]
p1 <- dim(fit$model)-1
P0 <- c(P0, p1)
}
P0 <- vector()
for(i in 1:length(m.block$c.models$weights)){
fit <- m.block$c.models$models[[i]]
p1 <- dim(fit$model)[2]-1
P0 <- c(P0, p1)
}
p2 <- P0 %*% m.block$c.models$weights
m.block$c.models$weights
load("H:/UbuntuRv2/STC/TCG/tcg_ar_method_2_1.RData")
P0 <- vector()
for(i in 1:length(m.block$c.models$weights)){
fit <- m.block$c.models$models[[i]]
p1 <- dim(fit$model)[2]-1
P0 <- c(P0, p1)
}
p2 <- P0 %*% m.block$c.models$weights
balanced.metric <- function(m){
precision <- m[1,1]/(m[1,1] + m[1,2])
recall    <- m[1,1]/(m[1,1] + m[2,1])
f.measure <- (2*precision*recall)/(precision + recall)
return(c(precision, recall, f.measure))
}
load("H:/UbuntuRv2/STC/TCG/tcg_ar_method_1_1.RData")
Pred <- predicts.Gibbs(data.test, m.block)
m1 <- binary.table(data.test$TC_genesis, Pred, type = "response")
binary.table <- function(y, y_pred, type = c("link", "response")){
m <- matrix(rep(0,4), ncol = 2)
rownames(m) <- c("Positive", "Negative")
colnames(m) <- c("True", "False")
if(type == "link"){
m[1,1] <- sum(y == 1 & y_pred > 0) #TP
m[1,2] <- sum(y == 0 & y_pred > 0) #FP
m[2,1] <- sum(y == 1 & y_pred < 0) #FN
m[2,2] <- sum(y == 0 & y_pred < 0) #TN
}
else{
m[1,1] <- sum(y == 1 & y_pred > 0.5)
m[1,2] <- sum(y == 0 & y_pred > 0.5)
m[2,1] <- sum(y == 1 & y_pred < 0.5)
m[2,2] <- sum(y == 0 & y_pred < 0.5)
}
return(m)
}
balanced.metric <- function(m){
precision <- m[1,1]/(m[1,1] + m[1,2])
recall    <- m[1,1]/(m[1,1] + m[2,1])
f.measure <- (2*precision*recall)/(precision + recall)
return(c(precision, recall, f.measure))
}
m1 <- binary.table(data.test$TC_genesis, Pred, type = "response")
load("H:/UbuntuRv2/STC/TCG/tcg_ar_method_2_1.RData")
m2 <- binary.table(data.test$TC_genesis, Pred, type = "response")
Pred <- predicts.Gibbs(data.test, m.block)
m2 <- binary.table(data.test$TC_genesis, Pred, type = "response")
load("H:/UbuntuRv2/STC/TCG/tcg_ar_method_3_1.RData")
m3 <- binary.table(data.test$TC_genesis, Pred.t, type = "link")
imbalanced.metric <- function(m){
precision <- m[1,1]/(m[1,1] + m[1,2])
recall    <- m[1,1]/(m[1,1] + m[2,1])
f.measure <- (2*precision*recall)/(precision + recall)
return(c(precision, recall, f.measure))
}
m4 <- rbind(imbalanced.metric(m1),imbalanced.metric(m2),imbalanced.metric(m3))
m4
stargazer::stargazer(m4)
sum((tcg$TC_genesis))
2504-238
devtools::check()
